{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 9: Ridge and Lasso Regularization in Scikit-Learn\n",
    "***\n",
    "\n",
    "<img src=\"figs/cogs.jpg\" width=1100 height=50>\n",
    "\n",
    "**Reminder**:  Go to the botttom of the notebook and shift-enter the helper functions.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Dam Ridge Regression\n",
    "***\n",
    "\n",
    "We'll again study the data set describing water level in a damn to the rate of flow of water through the damn. First we'll load the data which is stored in a serialized format in the data directory.  We'll store the features in a 2D Numpy array $X$ and the response in a 1D Numpy array $y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import damn data \n",
    "with open(\"data/dam_regression.pickle\", \"rb\") as fname: dam_data = pickle.load(fname)\n",
    "X = dam_data[\"features\"]\n",
    "y = dam_data[\"response\"]\n",
    "\n",
    "# train-validation split \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1734)\n",
    "\n",
    "# plot the data \n",
    "dam_plot([(X_train, y_train, \"training\"), (X_valid, y_valid, \"validation\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Next we'll build a polynomial regression model to fit the data. Anticipating that we may want to do $\\ell_2$-regularization at a later time, we'll use Scikit-Learn's [Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) class. Use the link to check out the documentation. Notice that the class can be instantiated with several parameters, including a regularization parameter `alpha` (which is what we, and the rest of the civilized world, call $\\lambda$). In addition to creating the polynomial features, we'll also standardize the features so that they play nicer with regularization.   \n",
    "\n",
    "As a first pass, and to create a baseline, we'll start with a linear model with no regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "degree, alpha = 1, 0\n",
    "polyregcombo = [(\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "                (\"standardization\", StandardScaler()),\n",
    "                (\"ridge\", Ridge(alpha=alpha))]\n",
    "\n",
    "linregpipe = Pipeline(polyregcombo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've only created an instance of the class.  Next we need to fit the model to our data.  Almost all models in Scikit-Learn come with a `.fit` method used to train the model.  We need to pass in the training features in `X_train` and the training responses in `y_train`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linregpipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Next we'll make predictions on the training and validation sets and evaluate the mean-squared error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "yhat_train = linregpipe.predict(X_train)\n",
    "yhat_valid = linregpipe.predict(X_valid)\n",
    "\n",
    "mse_train = mean_squared_error(yhat_train, y_train)\n",
    "mse_valid = mean_squared_error(yhat_valid, y_valid)\n",
    "\n",
    "print(\"Training MSE:   {:.3f}\".format(mse_train))\n",
    "print(\"Validation MSE: {:.3f}\".format(mse_valid))\n",
    "\n",
    "xplot = np.linspace(-60,60,100).reshape(-1,1)\n",
    "yplot = linregpipe.predict(xplot) \n",
    "dam_plot([(X_train, y_train, \"training\"), (X_valid, y_valid, \"validation\")], [(xplot, yplot, \"model\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Next we'll fit a high-degree polynomial model with no regularization, which is very likely to overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree, alpha = 9, 0\n",
    "stand_combo = [(\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "               (\"stand\", StandardScaler()),\n",
    "               (\"ridge\", Ridge(alpha=alpha))]\n",
    "deg9regpipe = Pipeline(stand_combo)\n",
    "\n",
    "deg9regpipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll fit the model, print errors, and make a plot. How do the resulting errors and plot compare to the linear model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = deg9regpipe.predict(X_train)\n",
    "yhat_valid = deg9regpipe.predict(X_valid)\n",
    "\n",
    "mse_train = mean_squared_error(yhat_train, y_train)\n",
    "mse_valid = mean_squared_error(yhat_valid, y_valid)\n",
    "\n",
    "print(\"Training MSE:   {:.3f}\".format(mse_train))\n",
    "print(\"Validation MSE: {:.3f}\".format(mse_valid))\n",
    "\n",
    "xplot = np.linspace(-60,60,100).reshape(-1,1)\n",
    "yplot = deg9regpipe.predict(xplot) \n",
    "dam_plot([(X_train, y_train, \"training\"), (X_valid, y_valid, \"validation\")], [(xplot, yplot, \"model\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Unsurprisingly, the degree-9 model appears to overfit the training data.  Let's see if we can temper it a bit by using regularization.  Go back to the previous block and play with the regularization strength.  Can you zero in on a value of `alpha` ($\\lambda$) that seems to work well? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Let's see how we can systematically zero in on a good regularization parameter for the degree $9$ model. Typically what we'd do is run our model for many values of the regularization parameter and examine the MSE on the training and validation sets.  The optimal regularization parameter is then the place on the curve with the lowest validation error.  Scikit-Learn implements this functionality using something called a [validation_curve](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html#sklearn.model_selection.validation_curve). \n",
    "\n",
    "Interpret the validation curve.  How does the regularization parameter affect the validation and training error?  What value of the regularization strength appears to be optimal? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "lams = np.linspace(0.01, 10, 20)\n",
    "\n",
    "neg_MSE_train_folds, neg_MSE_valid_folds = validation_curve(deg9regpipe, X, y, \n",
    "                                                            param_name=\"ridge__alpha\", param_range=lams,\n",
    "                                                            cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "MSE_train = -np.mean(neg_MSE_train_folds, axis=1)\n",
    "MSE_valid = -np.mean(neg_MSE_valid_folds, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))\n",
    "ax.plot(lams, MSE_train, lw=3, color=\"steelblue\", label=\"training\")\n",
    "ax.plot(lams, MSE_valid, lw=3, color=\"green\", label=\"validation\")\n",
    "ax.grid(alpha=0.25)\n",
    "ax.set_xlabel(\"regularization parameter\", fontsize=16)\n",
    "ax.set_ylabel(\"Error\", fontsize=16)\n",
    "ax.legend(loc=\"upper right\", fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Eyeball (or compute exactly, if you can) the optimal value of the regularization strength.  Then create a new regularized model using the desired value of $\\lambda,$ check MSE, make plots, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "degree, alpha = 9, 0 # TODO \n",
    "reg_combo= [(\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "            (\"stand\", StandardScaler()),\n",
    "            (\"ridge\", Ridge(alpha=alpha))]\n",
    "deg9optpipe = Pipeline(reg_combo)\n",
    "\n",
    "deg9optpipe.fit(X_train, y_train)\n",
    "\n",
    "yphat_train = deg9optpipe.predict(X_train)\n",
    "yphat_valid = deg9optpipe.predict(X_valid)\n",
    "\n",
    "print(\"Degree {:d} Train MSE:      {:.3f}\".format(degree, mean_squared_error(yphat_train, y_train)))\n",
    "print(\"Degree {:d} Validation MSE: {:.3f}\".format(degree, mean_squared_error(yphat_valid, y_valid)))\n",
    "\n",
    "xplot = np.linspace(-60,60,100).reshape(-1,1)\n",
    "yplot = deg9optpipe.predict(xplot) \n",
    "dam_plot([(X_train, y_train, \"training\"), (X_valid, y_valid, \"validation\")], [(xplot, yplot, \"model\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G**: Produce learning curves for the degree-9 polynomial model with no regularization and the one with optimal regularization strength.  Interpret the results in terms of the Bias-Variance Trade-Off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes = np.array([13+ii for ii in range(43-13)])\n",
    "\n",
    "train_sizes, neg_MSE_train_folds, neg_MSE_valid_folds = learning_curve(estimator=deg9regpipe, X=X, y=y,\n",
    "                                                        train_sizes=train_sizes, cv=10,\n",
    "                                                        scoring=\"neg_mean_squared_error\") \n",
    "\n",
    "MSE_train = -np.mean(neg_MSE_train_folds, axis=1)\n",
    "MSE_valid = -np.mean(neg_MSE_valid_folds, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))\n",
    "ax.plot(train_sizes, MSE_train, lw=3, color=\"steelblue\", label=\"training\")\n",
    "ax.plot(train_sizes, MSE_valid, lw=3, color=\"green\", label=\"validation\")\n",
    "ax.grid(alpha=0.25)\n",
    "ax.set_xlabel(\"training set size\", fontsize=16)\n",
    "ax.set_ylabel(\"Error\", fontsize=16)\n",
    "ax.legend(loc=\"upper right\", fontsize=16);\n",
    "ax.set_ylim([0,200]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is now a gigantic gap between the validation and training MSE, indicating that the method has **high variance** (as we would expect, since it's an unregularized high-degree polynomial regression).  Additionally, the training MSE is fairly low, indicating that the model has **low bias**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes = np.array(range(1,43))\n",
    "\n",
    "train_sizes, neg_MSE_train_folds, neg_MSE_valid_folds = learning_curve(estimator=deg9optpipe, X=X, y=y,\n",
    "                                                        train_sizes=train_sizes, cv=10,\n",
    "                                                        scoring=\"neg_mean_squared_error\") \n",
    "\n",
    "MSE_train = -np.mean(neg_MSE_train_folds, axis=1)\n",
    "MSE_valid = -np.mean(neg_MSE_valid_folds, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))\n",
    "ax.plot(train_sizes, MSE_train, lw=3, color=\"steelblue\", label=\"training\")\n",
    "ax.plot(train_sizes, MSE_valid, lw=3, color=\"green\", label=\"validation\")\n",
    "ax.grid(alpha=0.25)\n",
    "ax.set_xlabel(\"training set size\", fontsize=16)\n",
    "ax.set_ylabel(\"Error\", fontsize=16)\n",
    "ax.legend(loc=\"upper right\", fontsize=16);\n",
    "ax.set_ylim([0,20]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with regularization we now have a fairly small gap between the validation and training MSE, indicating that the method has fairly **low variance**.  The training MSE is again pretty low, indicating that the model has fairly **low bias**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Ridge Regression and Baseball Hitter Salaries\n",
    "***\n",
    "\n",
    "This problem was adopted from _Introduction to Statistical Learning_ by James, et. al. \n",
    "\n",
    "In this problem we'll look at how Ridge regularization affects the coefficients and performance of a multiple linear regression model to predict baseball salaries based on various stats. You can read descriptions of each of the features [here](https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Hitters.html). \n",
    "\n",
    "Execute the following cell to load the data into a Pandas DataFrame, inspect it, and convert the data into numerical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data and separate into features and response \n",
    "dfHitters = pd.read_csv(\"data/hitters.csv\")\n",
    "X, y = dfHitters.loc[:,dfHitters.columns != \"Salary\"].values*1.0, dfHitters.loc[:, \"Salary\"].values\n",
    "\n",
    "# check out data \n",
    "dfHitters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: The first thing we'll do is perform a regularization study with Ridge regression to see how the regression parameters behave as the regularization strength increases. Run the following code and describe the effect of the regularization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vector of lambdas \n",
    "lams = np.logspace(-3,9,100)\n",
    "\n",
    "# fit ridge regression model for each lambda and save coefficients \n",
    "rreg = Ridge(normalize=True)\n",
    "coefs = []\n",
    "for lam in lams:\n",
    "    rreg.set_params(alpha=lam)\n",
    "    rreg.fit(X, y)\n",
    "    coefs.append(rreg.coef_)\n",
    "\n",
    "# plot the trajectory of each coefficient vs lambda \n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "ax.plot(lams, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('regularization strength', fontsize=16)\n",
    "ax.set_ylabel('standardized coefficients', fontsize=16)\n",
    "plt.axis('tight')\n",
    "ax.grid(alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Next we'll look at the model parameters and model performance for various specific values of $\\lambda$. First we'll split the data into train and validation sets.  Then we'll fit a Ridge regression model with `lam = 4`.  Note the size of the parameters and the validation MSE. Next, set `lam` to a very very large value.  What do you observe?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into train and validation sets \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 4\n",
    "rreg= Ridge(alpha=lam, normalize=True)\n",
    "rreg.fit(X_train, y_train)\n",
    "pred_valid = rreg.predict(X_valid)\n",
    "\n",
    "valid_MSE = np.mean((y_valid - pred_valid)**2)\n",
    "print(\"Ridge (lam = {:f}) Validation MSE: {:.1f})\".format(lam, valid_MSE))\n",
    "\n",
    "coef_vis(rreg.coef_, dfHitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Is the regularization actually producing a better model?  Compare the validation MSE when `lam = 4` to the validation MSE for standard unregularized multiple linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0\n",
    "rreg= Ridge(alpha=lam, normalize=True)\n",
    "rreg.fit(X_train, y_train)\n",
    "pred_valid = rreg.predict(X_valid)\n",
    "\n",
    "valid_MSE = np.mean((y_valid - pred_valid)**2)\n",
    "print(\"Ridge (lam = {:f}) Validation MSE: {:.1f})\".format(lam, valid_MSE))\n",
    "\n",
    "coef_vis(rreg4lam.coef_, dfHitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Next we'll perform cross-validation to choose an optimal value of `lam`.  We could do this by plotting a validation curve, but Scikit-Learn actually has a built in routine for finding the optimal `lam` in Ridge Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "rregcv = RidgeCV(alphas = lams, scoring = 'neg_mean_squared_error', normalize = True)\n",
    "rregcv.fit(X_train, y_train)\n",
    "print(\"The optimal Ridge Regression Parameter is {:.3f}\".format(rregcv.alpha_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Use the optimal regularization parameter to fit a new model and evaluate the MSE on the validation data. Is this an improvement over the other models we've looked at? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = rregcv.alpha_\n",
    "rreg = Ridge(alpha=lam, normalize=True)\n",
    "rreg .fit(X_train, y_train)\n",
    "pred_valid = rreg.predict(X_valid)\n",
    "\n",
    "valid_MSE = np.mean((y_valid - pred_valid)**2)\n",
    "print(\"Ridge (lam = {:f}) Validation MSE: {:.1f})\".format(lam, valid_MSE))\n",
    "\n",
    "coef_vis(rreg.coef_, dfHitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Use the optimal value of `lam` to fit a model on the entirety of the data set.  Then inspect the model coefficients (better to print them then plot them).  What do you notice about the size of the model parameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Lasso and Baseball Hitter Salaries\n",
    "***\n",
    "\n",
    "This problem was adopted from _Introduction to Statistical Learning_ by James, et. al. \n",
    "\n",
    "We saw in the previous problem that Ridge Regression produces a better model than standard multiple linear regression.  Now we'll see how Lasso compares to the rest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: The we'll perform a regularization study with Lasso to see how the regression parameters behave as the regularization strength increases. Run the following code and describe the effect of the regularization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV \n",
    "\n",
    "# define vector of lambdas \n",
    "lams = np.logspace(-3,9,100)\n",
    "\n",
    "# fit ridge regression model for each lambda and save coefficients \n",
    "lreg = Lasso(normalize=True, max_iter=10000)\n",
    "coefs = []\n",
    "for lam in lams:\n",
    "    lreg.set_params(alpha=lam)\n",
    "    lreg.fit(X, y)\n",
    "    coefs.append(lreg.coef_)\n",
    "\n",
    "# plot the trajectory of each coefficient vs lambda \n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "ax.plot(lams, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('regularization strength', fontsize=16)\n",
    "ax.set_ylabel('standardized coefficients', fontsize=16)\n",
    "plt.axis('tight')\n",
    "ax.grid(alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Next we'll perform cross-validation to choose an optimal value of `lam`. Fit a Lasso model with the optimal regularization strength that you found.  Compute the validation MSE and compare it to the Ridge models you computed in Problem 2.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# run cross-validation and find optimal parameter \n",
    "lassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n",
    "lassocv.fit(X_train, y_train)\n",
    "\n",
    "print(\"The optimal Lasso Parameter is {:.3f}\".format(lassocv.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit Lasso model with optimal regularization strength \n",
    "lasso = Lasso(normalize=True, alpha=lassocv.alpha_, max_iter=100000)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# make predictions \n",
    "pred_valid = lasso.predict(X_valid)\n",
    "\n",
    "# compute MSE \n",
    "valid_MSE = np.mean((y_valid - pred_valid)**2)\n",
    "print(\"Lasso (lam = {:f}) Validation MSE: {:.1f})\".format(lassocv.alpha_, valid_MSE))\n",
    "\n",
    "# plot coefficients \n",
    "coef_vis(lasso.coef_, dfHitters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: The best validation MSE from Lasso is better than standard MLR, but is a little worse than the optimal result with Ridge Regression.  Why would we ever choose Lasso over Ridge regression then? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br>\n",
    "<br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "### Helper Functions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dam_plot(scatter=[], models=[]):\n",
    "    '''\n",
    "    Function to plot the dam data \n",
    "    '''\n",
    "    \n",
    "    # colors for scatter plots and model plots \n",
    "    scolors = [\"steelblue\", \"#a76c6e\", \"#6a9373\", \"orange\"]\n",
    "    mcolors = [\"black\", \"gray\"]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))\n",
    "    \n",
    "    # Loop over scatter data and make plots \n",
    "    for ii, (x, y, label) in enumerate(scatter):\n",
    "        ax.scatter(x, y, s=100, color=scolors[ii], label=label, zorder=2)\n",
    "        \n",
    "    # Loop over model data and make plots \n",
    "    for ii, (xplot, yplot, label) in enumerate(models):\n",
    "        ax.plot(xplot, yplot, color=mcolors[ii], lw=3, label=label, zorder=1)\n",
    "        \n",
    "    # Set axis limits\n",
    "    ax.set_xlim([-60,60])\n",
    "    ax.set_ylim([-5,60])\n",
    "        \n",
    "    # Label all the things \n",
    "    ax.set_xlabel(\"change in water level\", fontsize=16)\n",
    "    ax.set_ylabel(\"water flowing out of damn\", fontsize=16)\n",
    "    ax.set_title(\"Dam Data\", fontsize=20); ax.grid(alpha=0.25)\n",
    "    ax.legend(loc=\"upper left\", fontsize=12);\n",
    "    \n",
    "def coef_vis(coef, df):\n",
    "    '''\n",
    "    Function to plot MLR parameters \n",
    "    '''\n",
    "    feat_names = df.columns.values[:-1]\n",
    "    sinds = np.argsort(coef)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,6))\n",
    "    ax.bar(range(len(coef)), coef[sinds], color=\"steelblue\", align=\"center\")\n",
    "    ax.set_ylabel(\"standardized coefficient\", fontsize=16)\n",
    "    ax.grid(alpha=0.25)\n",
    "    ax.set_xticks(range(len(coef)))\n",
    "    ax.set_xticklabels(feat_names[sinds], rotation='vertical', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
